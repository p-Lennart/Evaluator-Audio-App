# Pitch Detection Benchmarking Framework

This framework provides a standardized way to benchmark different pitch detection algorithms (PDAs) against a suite of synthetic audio test cases.

## Features

*   **Synthetic Test Data Generation:** Generate audio files with known ground-truth pitch contours for reliable evaluation.
*   **Pluggable Algorithms:** Easily integrate and compare various pitch detection algorithms.
*   **Automated Evaluation:** Run all selected algorithms against the test suite and get performance metrics using `mir_eval`.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd pitch_detection_benchmarking
    ```
2.  **Create and activate a Python virtual environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
3.  **Install dependencies:**
    ```bash
    pip install numpy scipy mir_eval aubio
    ```
    *Note: `aubio` is required for the default Aubio PDA. If you plan to only use other algorithms, you might not need it, but it's good for a complete setup.*

## Usage

### 1. Generate Test Data

First, generate the synthetic audio files and their corresponding ground-truth annotations. These will be stored in the `data/test_suite/` directory.

```bash
python3 generate_test_data.py
```

You can customize the types of test data generated by modifying `generate_test_data.py`.

### 2. Run the Benchmark

Once the test data is generated, you can run the benchmark. This script will iterate through all registered pitch detection algorithms, run them on each test audio file, and then evaluate their performance using `mir_eval`.

```bash
python3 evaluate_pitch.py
```

The output will display performance metrics for each algorithm on each test case. Estimated pitch files will be saved in `results/<AlgorithmName>/`.

## Adding a New Pitch Detection Algorithm

The framework is designed to be easily extensible. To benchmark a new pitch detection algorithm:

1.  **Create a new Python file** in the `algorithms/` directory. For example, if you want to add an algorithm named "MyAwesomePDA", create `algorithms/my_awesome_pda.py`.

2.  **Implement the `run_pitch_detection` function** in your new file. This function must adhere to the following signature:

    ```python
    # algorithms/my_awesome_pda.py

    import subprocess
    # Import any other libraries your PDA needs

    def run_pitch_detection(audio_path: str, output_path: str) -> bool:
        """
        Runs the pitch detection algorithm on the given audio file and
        saves the pitch annotations to output_path.

        Args:
            audio_path (str): The path to the input audio file (.wav).
            output_path (str): The path where the pitch annotations
                                (timestamp\tfrequency format) should be saved.

        Returns:
            bool: True if the algorithm ran successfully, False otherwise.
        """
        print(f"Running MyAwesomePDA on {audio_path}...")
        try:
            # Replace this with the actual command or Python code for your PDA
            # Example using a hypothetical command-line tool:
            # command = ['my_awesome_pda_cli', '--input', audio_path, '--output', output_path]
            # subprocess.run(command, check=True)

            # Example using a Python library:
            # from my_awesome_library import detect_pitch
            # pitches = detect_pitch(audio_path)
            # with open(output_path, 'w') as f:
            #     for time, freq in pitches:
            #         f.write(f"{time:.3f}\t{freq:.3f}\n")

            # For demonstration, let's just copy the ground truth (DO NOT DO THIS IN REAL BENCHMARKING!)
            # This is just to make the example run without a real PDA
            with open(audio_path.replace('.wav', '_ground_truth.txt'), 'r') as gt_file:
                with open(output_path, 'w') as out_file:
                    out_file.write(gt_file.read())
            
            return True
        except Exception as e:
            print(f"Error running MyAwesomePDA: {e}")
            return False
    ```
    **Important:** The `output_path` file *must* contain pitch annotations in the `timestamp<tab>frequency` format that `mir_eval` expects. Frequencies should be in Hz, and unvoiced frames should be represented by `0.0` or non-positive values.

3.  **Register your algorithm** in `evaluate_pitch.py`. Open `evaluate_pitch.py` and locate the `algorithms_to_benchmark` list. Add an entry for your new algorithm:

    ```python
    # evaluate_pitch.py

    algorithms_to_benchmark = [
        {'name': 'Aubio', 'module': 'algorithms.aubio'},
        {'name': 'MyAwesomePDA', 'module': 'algorithms.my_awesome_pda'}, # Add this line
    ]
    ```

Now, when you run `python3 evaluate_pitch.py`, your new algorithm will be included in the benchmark!
